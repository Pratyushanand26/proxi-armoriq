# PROJECT OVERVIEW: Proxi - The Context-Aware Cloud Guardian

## ğŸ“¦ Complete File Manifest

```
proxi-armoriq/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                     # Comprehensive documentation
â”œâ”€â”€ ğŸ“„ QUICKSTART.md                 # 60-second setup guide
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ“„ .env.example                  # Optional LLM configuration
â”œâ”€â”€ ğŸ“„ .gitignore                    # Git ignore rules
â”œâ”€â”€ ğŸš€ main.py                       # Demo orchestration script
â”œâ”€â”€ ğŸ§ª test_installation.py          # Verification script
â”‚
â”œâ”€â”€ ğŸ“ policies/
â”‚   â””â”€â”€ ops_policy.json             # Security policy definition (JSON)
â”‚
â””â”€â”€ ğŸ“ src/
    â”œâ”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ ğŸ“ guardrails/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ policy_engine.py        # Core policy enforcement (187 lines)
    â”‚
    â”œâ”€â”€ ğŸ“ mcp_server/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ tools.py                # Mock cloud infrastructure (240 lines)
    â”‚   â””â”€â”€ server.py               # FastAPI MCP server (233 lines)
    â”‚
    â””â”€â”€ ğŸ“ agent/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ bot.py                  # LangChain AI agent (352 lines)
```

**Total Code**: ~1,000+ lines of production-ready Python

---

## ğŸ¯ Design Philosophy

### 1. Security First
Every action must pass through policy validation **before** execution. The policy engine is not a suggestion - it's a hard constraint.

### 2. Separation of Concerns
- **Policy Engine**: Knows about security rules
- **MCP Server**: Knows about tool execution
- **AI Agent**: Knows about problem-solving
- **Tools**: Know about infrastructure

### 3. Fail-Safe Design
- Invalid tool â†’ Blocked
- Wrong mode â†’ Blocked  
- Destructive operation â†’ Always blocked
- No way to bypass the policy

### 4. Transparency
The agent doesn't just fail - it explains **why** an action was blocked and suggests alternatives.

---

## ğŸ” Security Model

### Policy Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GLOBAL RULES (Always Apply)                    â”‚
â”‚  â€¢ delete_database: ALWAYS BLOCKED              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MODE-BASED RULES (Context Dependent)            â”‚
â”‚                                                  â”‚
â”‚  NORMAL MODE:                                    â”‚
â”‚    âœ… get_service_status, read_logs             â”‚
â”‚    âŒ restart_service, scale_fleet              â”‚
â”‚                                                  â”‚
â”‚  EMERGENCY MODE:                                 â”‚
â”‚    âœ… get_service_status, read_logs,            â”‚
â”‚       restart_service, scale_fleet              â”‚
â”‚    âŒ (none beyond global)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Validation Flow

```python
1. User requests: "Restart the server"
2. Agent decides: Use restart_service tool
3. MCP Server calls: policy_engine.validate("restart_service")
4. Policy Engine checks:
   - Is it globally blocked? (No)
   - Is it blocked in current mode? (Yes in NORMAL, No in EMERGENCY)
5. Result:
   - If blocked: Raise PolicyViolationError
   - If allowed: Execute tool
6. Agent receives response and explains to user
```

---

## ğŸ—ï¸ Component Deep Dive

### Policy Engine (`src/guardrails/policy_engine.py`)

**Purpose**: Single source of truth for security policies

**Key Methods**:
- `validate(tool_name, args, context)`: Main enforcement function
- `set_mode(mode)`: Change operational context
- `get_allowed_tools()`: Query current permissions
- `get_policy_summary()`: Human-readable status

**Why it's good**:
- Declarative policy definition (JSON)
- Single responsibility (security only)
- Easy to audit and modify
- Zero bypass mechanisms

### MCP Server (`src/mcp_server/server.py`)

**Purpose**: Expose tools to the agent with policy enforcement

**Architecture**:
```python
@app.post("/tools/execute")
async def execute_tool(request: ToolRequest):
    # 1. VALIDATE FIRST (Critical!)
    policy_engine.validate(tool_name, args)
    
    # 2. Only execute if validation passed
    result = execute_tool_function(tool_name, args)
    
    # 3. Return result
    return ToolResponse(success=True, result=result)
```

**Why it's good**:
- Policy check is first (fail fast)
- Clean REST API
- Structured responses
- Tool catalog for discovery

### AI Agent (`src/agent/bot.py`)

**Purpose**: Intelligent problem-solving within constraints

**Features**:
- LangChain integration
- Mock LLM for demo (no API keys needed)
- Transparent reasoning process
- Graceful policy violation handling

**Why it's good**:
- Explains policy blocks to users
- Suggests alternatives when blocked
- Shows decision-making process
- Works with real or mock LLM

### Mock Infrastructure (`src/mcp_server/tools.py`)

**Purpose**: Simulate realistic cloud operations

**Tools Provided**:
- `get_service_status`: Check service health
- `read_logs`: View system logs
- `restart_service`: Restart services
- `scale_fleet`: Adjust capacity
- `delete_database`: Destructive operation

**Why it's good**:
- Realistic behavior
- Audit logging
- Detailed responses
- Easy to extend

---

## ğŸ¬ Demo Scenarios Explained

### Scenario 1: Normal Mode Block

**Setup**:
- Mode: NORMAL (read-only)
- Task: "Restart the web server"

**Flow**:
1. Agent analyzes task â†’ needs restart_service
2. Agent calls MCP server
3. MCP server calls policy_engine.validate("restart_service")
4. Policy engine checks: "restart_service" in NORMAL mode blocked list? YES
5. Raises PolicyViolationError
6. MCP server returns: "POLICY BLOCKED"
7. Agent receives block â†’ explains to user

**Learning**: Read-only mode prevents accidental changes

### Scenario 2: Emergency Mode Success

**Setup**:
- Mode: EMERGENCY
- Incident: Web server critical
- Task: "Fix the critical web server issue"

**Flow**:
1. Agent analyzes task â†’ needs restart_service
2. Agent calls MCP server  
3. MCP server calls policy_engine.validate("restart_service")
4. Policy engine checks: "restart_service" in EMERGENCY mode allowed list? YES
5. Validation passes
6. Tool executes â†’ service restarted
7. Agent reports success

**Learning**: Context-aware permissions enable appropriate responses

### Scenario 3: Always Blocked

**Setup**:
- Mode: EMERGENCY (permissive)
- Task: "Delete the database to clear space"

**Flow**:
1. Agent analyzes task â†’ needs delete_database
2. Agent calls MCP server
3. MCP server calls policy_engine.validate("delete_database")
4. Policy engine checks: "delete_database" in global blocked list? YES
5. Raises PolicyViolationError (always)
6. MCP server returns: "POLICY BLOCKED"
7. Agent explains + suggests alternatives

**Learning**: Some operations are never allowed (defense in depth)

---

## ğŸ’¡ Innovation Highlights

### 1. Hard Constraints, Not Soft Prompts
Unlike prompt-based "please don't do X", this uses actual code enforcement.

### 2. Context Awareness
Permissions adapt to operational context (normal vs emergency).

### 3. Agent Transparency
Agent doesn't silently fail - it explains the "why" behind blocks.

### 4. Declarative Security
Policies defined in JSON, easy to audit and modify without code changes.

### 5. Production-Ready Architecture
Proper separation of concerns, error handling, logging, and testing.

---

## ğŸ”¬ Technical Decisions

### Why FastAPI for MCP Server?
- Modern Python web framework
- Automatic API documentation (visit `/docs`)
- Type safety with Pydantic
- Easy to extend

### Why LangChain for Agent?
- Standard agent framework
- Tool calling built-in
- Easy to swap LLM providers
- Good documentation

### Why JSON for Policies?
- Human readable
- Easy to version control
- Can be edited without code knowledge
- Supports comments (with preprocessor)

### Why Mock LLM Option?
- Demo works without API keys
- Faster iteration during development
- Deterministic behavior for testing
- Easy to understand agent logic

---

## ğŸ“Š Success Metrics

This project successfully demonstrates:

âœ… **Policy Enforcement**: 100% of tool calls validated  
âœ… **Context Awareness**: Mode switching works correctly  
âœ… **Safety**: Destructive operations always blocked  
âœ… **Agent Intelligence**: Reasoning and explanation  
âœ… **Code Quality**: Clean, documented, testable  
âœ… **Usability**: Works out of the box (no config needed)  

---

## ğŸš€ Future Enhancements

### Advanced Policies
- Time-based rules (no destructive ops during business hours)
- Parameter validation (max scale: 10 instances)
- User-based permissions (admin vs operator)
- Cost-based constraints (budget limits)

### Real Integrations
- AWS/GCP/Azure cloud APIs
- Kubernetes operations
- Database management
- Monitoring and alerting

### Enhanced Agent
- Multi-step planning
- Learning from past blocks
- Policy suggestion ("should I enable emergency mode?")
- Interactive policy negotiation

### Production Features
- Audit logging
- Metrics and monitoring
- Multi-tenancy
- Policy versioning
- Rollback capabilities

---

## ğŸ“ Educational Value

This project teaches:

1. **AI Safety**: Building guardrails that actually work
2. **System Design**: Separation of concerns, clear APIs
3. **Security Engineering**: Defense in depth, fail-safe defaults
4. **Agent Architecture**: How LLM agents interact with tools
5. **Python Best Practices**: Type hints, error handling, documentation

---

## ğŸ“ Support

For questions or issues:
1. Check `README.md` for detailed documentation
2. Run `test_installation.py` to verify setup
3. Review `QUICKSTART.md` for common issues
4. Examine the code - it's well commented!

---

**Built with â¤ï¸ for ArmorIQ Hackathon**

*Proxi: Because even AI agents need guardrails* ğŸ›¡ï¸
